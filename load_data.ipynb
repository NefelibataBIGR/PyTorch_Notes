{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image # 一个读取图片的库\n",
    "import os # 导入关于系统的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset?? # 可以查看工具的作用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*根据提示，需要自己定义一个类继承 Dataset类，修改__init__、\\__getitem__、__len__这几个方法，让自己的类可以读取数据与标签值*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**可以边用控制台调试边写（Python REPL）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(Dataset):\n",
    "    '''\n",
    "    创建自己的数据集读取类\n",
    "    '''\n",
    "    def __init__(self, root_dir, label_dir): # 定义类里面的全局变量，观察到labels就是文件夹的名称\n",
    "        self.root_dir = root_dir # 根目录，这里是训练集的文件夹路径\n",
    "        self.label_dir = label_dir # 数据集所在文件夹名字，这里是标签名\n",
    "        self.path = os.path.join(self.root_dir, self.label_dir) # 获取图片所在文件，这里文件名就是标签\n",
    "        self.image_path_list = os.listdir(self.path) # 获取所有图片的名字组成列表\n",
    "    \n",
    "    def __getitem__(self, index): # 获取某一个图片，index为索引\n",
    "        image_name = self.image_path_list[index]\n",
    "        image_item_path = os.path.join(self.path, image_name)\n",
    "        image = Image.open(image_item_path)\n",
    "        label = self.label_dir\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self): # 返回数据集的长度\n",
    "        return len(self.image_path_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r\"hymenoptera_data\\train\"\n",
    "ants_label_dir = \"ants\"\n",
    "bees_label_dir = \"bees\"\n",
    "ants_dataset = MyData(root_dir, ants_label_dir) # 获取蚂蚁数据集\n",
    "bees_dataset = MyData(root_dir, bees_label_dir) # 获取蜜蜂数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ants_dataset + bees_dataset # 两个数据集合并，合成训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_dataset[123] # 获取某一索引的数据\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*以下是用Python REPL的调试过程（逐行运行），注意将self删除再运行*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# image_path = \"E:\\\\Programming\\\\python\\\\pytorch\\\\hymenoptera_data\\\\train\\\\ants\\\\0013035.jpg\"\n",
    "# image = Image.open(image_path)\n",
    "# image.size\n",
    "# image.show()\n",
    "# dir_path = r\"hymenoptera_data\\train\\ants\" # 这里r防止\\转义\n",
    "# import os\n",
    "# image_path_list = os.listdir(dir_path) # 文件夹下所有文件名称作为列表输出\n",
    "# image_path_list[0]\n",
    "# root_dir = r\"hymenoptera_data\\train\" # 训练集文件夹\n",
    "# label_dir = \"ants\" # 标签名称\n",
    "# path = os.path.join(root_dir, label_dir) # 将两个路径合成拼接\n",
    "# image_path_list = os.listdir(path) # 获取所有图片的名字组成列表\n",
    "# index = 0\n",
    "# image_name = image_path_list[index]\n",
    "# image_item_path = os.path.join(path, image_name)\n",
    "# image = Image.open(image_item_path)\n",
    "# label = label_dir\n",
    "# len(image_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*写完class后，接着运行调试*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整段运行\n",
    "# from torch.utils.data import Dataset\n",
    "# from PIL import Image # 一个读取图片的库\n",
    "# import os # 导入关于系统的库\n",
    "# class MyData(Dataset):\n",
    "#     '''\n",
    "#     创建自己的数据集读取类\n",
    "#     '''\n",
    "#     def __init__(self, root_dir, label_dir): # 定义类里面的全局变量，观察到labels就是文件夹的名称\n",
    "#         self.root_dir = root_dir # 根目录，这里是训练集的文件夹路径\n",
    "#         self.label_dir = label_dir # 数据集所在文件夹名字，这里是标签名\n",
    "#         self.path = os.path.join(self.root_dir, self.label_dir) # 获取图片所在文件，这里文件名就是标签\n",
    "#         self.image_path_list = os.listdir(self.path) # 获取所有图片的名字组成列表\n",
    "    \n",
    "#     def __getitem__(self, index): # 获取某一个图片，index为索引\n",
    "#         image_name = self.image_path_list[index]\n",
    "#         image_item_path = os.path.join(self.path, image_name)\n",
    "#         image = Image.open(image_item_path)\n",
    "#         label = self.label_dir\n",
    "#         return image, label\n",
    "    \n",
    "#     def __len__(self): # 返回数据集的长度\n",
    "#         return len(self.image_path_list)\n",
    "    \n",
    "# root_dir = r\"hymenoptera_data\\train\"\n",
    "# ants_label_dir = \"ants\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 逐行运行\n",
    "# ants_dataset = MyData(root_dir, ants_label_dir) # 包括所有初始化变量\n",
    "# ants_dataset[0] # 与ants_dataset.__getitem__(0)作用相同，返回的是image和label\n",
    "# image, label = ants_dataset[0]\n",
    "# image.show()\n",
    "# image, label = ants_dataset[1]\n",
    "# image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整段运行\n",
    "# root_dir = r\"hymenoptera_data\\train\"\n",
    "# ants_label_dir = \"ants\"\n",
    "# bees_label_dir = \"bees\"\n",
    "# ants_dataset = MyData(root_dir, ants_label_dir)\n",
    "# bees_dataset = MyData(root_dir, bees_label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 逐行运行\n",
    "# image, label = bees_dataset[1]\n",
    "# image.show()\n",
    "# train_dataset = ants_dataset + bees_dataset # 两个数据集合并\n",
    "# len(train_dataset)\n",
    "# len(ants_dataset)\n",
    "# len(bees_dataset)\n",
    "# image, label = train_dataset[123]\n",
    "# image.show()\n",
    "# image, label = train_dataset[124]\n",
    "# image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.6196, 0.6235, 0.6471,  ..., 0.5373, 0.4941, 0.4549],\n",
       "          [0.5961, 0.5922, 0.6235,  ..., 0.5333, 0.4902, 0.4667],\n",
       "          [0.5922, 0.5922, 0.6196,  ..., 0.5451, 0.5098, 0.4706],\n",
       "          ...,\n",
       "          [0.2667, 0.1647, 0.1216,  ..., 0.1490, 0.0510, 0.1569],\n",
       "          [0.2392, 0.1922, 0.1373,  ..., 0.1020, 0.1137, 0.0784],\n",
       "          [0.2118, 0.2196, 0.1765,  ..., 0.0941, 0.1333, 0.0824]],\n",
       " \n",
       "         [[0.4392, 0.4353, 0.4549,  ..., 0.3725, 0.3569, 0.3333],\n",
       "          [0.4392, 0.4314, 0.4471,  ..., 0.3725, 0.3569, 0.3451],\n",
       "          [0.4314, 0.4275, 0.4353,  ..., 0.3843, 0.3725, 0.3490],\n",
       "          ...,\n",
       "          [0.4863, 0.3922, 0.3451,  ..., 0.3804, 0.2510, 0.3333],\n",
       "          [0.4549, 0.4000, 0.3333,  ..., 0.3216, 0.3216, 0.2510],\n",
       "          [0.4196, 0.4118, 0.3490,  ..., 0.3020, 0.3294, 0.2627]],\n",
       " \n",
       "         [[0.1922, 0.1843, 0.2000,  ..., 0.1412, 0.1412, 0.1294],\n",
       "          [0.2000, 0.1569, 0.1765,  ..., 0.1216, 0.1255, 0.1333],\n",
       "          [0.1843, 0.1294, 0.1412,  ..., 0.1333, 0.1333, 0.1294],\n",
       "          ...,\n",
       "          [0.6941, 0.5804, 0.5373,  ..., 0.5725, 0.4235, 0.4980],\n",
       "          [0.6588, 0.5804, 0.5176,  ..., 0.5098, 0.4941, 0.4196],\n",
       "          [0.6275, 0.5843, 0.5176,  ..., 0.4863, 0.5059, 0.4314]]]),\n",
       " 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = torchvision.datasets.CIFAR10(root=\"./my_cifar10\", train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset=test_set, batch_size=4, shuffle=True, num_workers=0, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 32, 32])\n",
      "tensor([7, 4, 2, 6])\n",
      "torch.Size([4, 3, 32, 32])\n",
      "tensor([0, 0, 0, 5])\n",
      "torch.Size([4, 3, 32, 32])\n",
      "tensor([5, 9, 2, 2])\n",
      "torch.Size([4, 3, 32, 32])\n",
      "tensor([5, 2, 7, 6])\n",
      "torch.Size([4, 3, 32, 32])\n",
      "tensor([8, 0, 5, 9])\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for data in test_loader:\n",
    "    i = i + 1\n",
    "    images, targets = data\n",
    "    print(images.shape)\n",
    "    print(targets)\n",
    "    \n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset=test_set, batch_size=64, shuffle=True, num_workers=0, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_loader = SummaryWriter(\"dataloader\")\n",
    "step = 0\n",
    "\n",
    "for epoch in range(2):\n",
    "    for data in test_loader:\n",
    "        images, targets = data\n",
    "        writer_loader.add_images(\"epoch:{}\".format(epoch), images, step)\n",
    "        step = step + 1\n",
    "\n",
    "writer_loader.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*可以看到shuffle=True时随机取数据*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
